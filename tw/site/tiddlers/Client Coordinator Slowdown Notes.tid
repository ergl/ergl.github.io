created: 20190226140606002
modified: 20190228234039150
tags: pvc_client_coordinator imdea
title: Client Coordinator Slowdown Notes
type: text/vnd.tiddlywiki

Running into the problem of slow performance between single site and multi site performance.

---

''The maximum number of concurrent clients for Single Site is around 1,200''

''The maximum number of concurrent clients for Two Sites is around 2,400''

Saturation points (''ping'')

| !Clusters (Delay ms) | !Case | !Clients (Total) | !Th | !Lat (ms) |
| 1 (0) | pvc-ccoord | 300 (1,200) | ~760K | ~1.7 |
| 2 (10) | pvc-ccoord | 600 (2,400) | ~341K | ~7.11 |

---

Saturation points (''readonly'')

| !Clusters (Delay ms) | !Case | !Clients (Total) | !Th | !Lat (ms) |
| 1 (0) | pvc-ccoord | 300 (1,200) | ~607.2K | ~2.1 |
| 2 (10) | pvc-ccoord | 400 (1,600) | ~230.4k | ~7.15 |

Could it be that we're hitting a limit in the number of concurrent connections? The number of concurrent clients is about the same (1,200 vs 1,600). It's normal that with higher base latency, we would need more concurrent clients to reach the same throughput. If we need 1.2k for 600k on 0ms, how many would we need for the same on 10ms?

To test:

* Determine ''maximum concurrent connections on single site'', using a ping message (or reuse read and return empty).
** The overhead of reading from ETS shouldn't be too much, since on our experiments, that path only takes 0.125 ms, or about 2% of the execution time.
** So the number of concurrent clients should be about the same (~1.2k).
** ''Make sure the client is still spawning / committing empty transactions''
*** We don't want to change the client, should do the same allocation pattern.

* Determine ''maximum concurrent connections on two sites'' (ping again).
** If the number of concurrent clients is the same (~1.6k), then we know our limit is the number of concurrent connections, ''but only if we get a number in the same ballpark as the single site scenario''.

---

Misc

* Is it an abort issue?
* Dissect latencies
* Add more client machines
** Figure out who's getting overloaded
* Increase read replicas?
** Shut off readitem_server (old replicas)
** Shut off things we don't need (coordinator pool, etc)

---

The difference comes from the fact that Antidote is returning the entire value of the key. In our case, that's 256KB, quite a lot of data. This explains the difference we had between the client coordinator approach and the client noproxy setting (at 600 clients we had 332,796.3 / 7.483251 (noproxy) vs 230,680.2 / 10.60521 (ccoord)
